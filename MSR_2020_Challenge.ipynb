{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MSR 2020 Challenge",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B0fLTyx59Rt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c9208c9a-d287-40d0-f5ed-e1c23ce020b2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzGFZE-HDJOV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df6dc2c2-c6ea-4bfd-f0e4-a35c50260228"
      },
      "source": [
        "cd drive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuR3LQI3NloD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a391505d-f3f3-4e9a-f4bb-6430bb4b228f"
      },
      "source": [
        "cd My Drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoNXnsXjNo6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5084c1aa-b717-4223-8372-fd6037552aa9"
      },
      "source": [
        "cd 520"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/520\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxsgoCnW5-_C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "774c3981-bfdf-41a5-ba78-8be39760f3df"
      },
      "source": [
        "import csv \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "fields=[]\n",
        "rows= []\n",
        "distribution = [] \n",
        "parent_rank = [] \n",
        "def success():\n",
        "    weight_of_actions = np.array(probabilities)\n",
        "    sum_of_probabilities = weight_of_actions.sum()\n",
        "    np.multiply(weight_of_actions, 1 / sum_of_probabilities, weight_of_actions)\n",
        "    cum_probabilities = weight_of_actions.cumsum()\n",
        "    x = random()\n",
        "    for i in range(len(cum_probabilities)):\n",
        "        if x < cum_probabilities[i]:\n",
        "            return ActualActions[i]\n",
        "with open(\"input.csv\", 'r') as csvfile: \n",
        "    # creating a csv reader object \n",
        "    csvreader = csv.reader(csvfile)\n",
        "    for row in csvreader: \n",
        "        rows.append(row) \n",
        "    print(len(rows))\n",
        "    for i in range(len(rows)):\n",
        "      distribution.append(success())\n",
        "    print(distribution[:10])\n",
        "data=list()\n",
        "for i in range(len(rows)):\n",
        "  data.append(((distribution[i]),int(rows[i][0])))\n",
        "csvfile.close()\n",
        "with open(\"output.csv\", 'w') as csvfile:\n",
        "  csvwriter=csv.writer(csvfile) \n",
        "  csvwriter.writerows(data)\n",
        "csvfile.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1048576\n",
            "[2, 0, 2, 2, 0, 0, 1, 0, 2, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1idkON8WsxL"
      },
      "source": [
        "def loadcsv():\n",
        "  with open(\"input.csv\", 'r') as csvfile:\n",
        "    csvreader = csv.reader(csvfile)\n",
        "    dataset=list(csvreader)\n",
        "    for i in range(len(dataset)):\n",
        "      dataset[i] = [float(x) for x in dataset[i]]\n",
        "    csvfile.close()\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7hauuXJZXAq"
      },
      "source": [
        "import random as random\n",
        "def splitDataset(dataset, splitRatio):\n",
        "  trainSize = int(len(dataset) * splitRatio)\n",
        "  trainSet = []\n",
        "  copy = list(dataset)\n",
        "  while len(trainSet) < trainSize:\n",
        "    index = random.randrange(len(copy))\n",
        "    trainSet.append(copy.pop(index))\n",
        "  return [trainSet, copy]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6XhteOQZgEl"
      },
      "source": [
        "def separateByClass(dataset):\n",
        "  separated = {}\n",
        "  for i in range(len(dataset)):\n",
        "   vector = dataset[i]\n",
        "  if (vector[-1] not in separated):\n",
        "    separated[vector[-1]] = []\n",
        "    separated[vector[-1]].append(vector)\n",
        "  return separated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zh9IxpMiZjNT"
      },
      "source": [
        "def mean(numbers):\n",
        "  return sum(numbers)/float(len(numbers))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHU_yW-iZnRq"
      },
      "source": [
        "import math\n",
        "def stdev(numbers):\n",
        "  avg = mean(numbers)\n",
        "  variance = sum([pow(x-avg,2) for x in numbers])/(len(numbers))\n",
        "  return math.sqrt(variance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX5uwrdkZsKi"
      },
      "source": [
        "def summarize(dataset):\n",
        "  summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
        "  del summaries[-1]\n",
        "  return summaries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW0b7CfdZvJR"
      },
      "source": [
        "def summarizeByClass(dataset):\n",
        "  separated = separateByClass(dataset)\n",
        "  summaries = {}\n",
        "  for classValue, instances in separated.items():\n",
        "    summaries[classValue] = summarize(instances)\n",
        "  return summaries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS5Vg9K1ZxcR"
      },
      "source": [
        "def calculateProbability(x, mean, stdev):\n",
        "  exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
        "  return (1/(math.sqrt(2*math.pi)*stdev))*exponent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIrzHIfWZ2BI"
      },
      "source": [
        "def calculateClassProbabilities(summaries, inputVector):\n",
        "  probabilities = {}\n",
        "  for classValue, classSummaries in summaries.items():\n",
        "    probabilities[classValue] = 1\n",
        "  for i in range(len(classSummaries)):\n",
        "    mean, stdev = classSummaries[i]\n",
        "    x = inputVector[i]\n",
        "    probabilities[classValue] *= calculateProbability(x, mean, stdev)\n",
        "  return probabilities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWyDnD45Z6Xn"
      },
      "source": [
        "def predict(summaries, inputVector):\n",
        "  probabilities = calculateClassProbabilities(summaries, inputVector)\n",
        "  bestLabel, bestProb = None, -1\n",
        "  for classValue, probability in probabilities.items():\n",
        "    if bestLabel is None or probability > bestProb:\n",
        "      bestProb = probability\n",
        "      bestLabel = classValue\n",
        "  return bestLabel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvyyv-L5aFvg"
      },
      "source": [
        "def getPredictions(summaries, testSet):\n",
        "  predictions = []\n",
        "  for i in range(len(testSet)):\n",
        "    result = predict(summaries, testSet[i])\n",
        "    predictions.append(result)\n",
        "  return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE4FD-o3aHIp"
      },
      "source": [
        "def getAccuracy(testSet, predictions):\n",
        "  correct = 0\n",
        "  for x in range(len(testSet)):\n",
        "    if testSet[x][-1] == predictions[x]:\n",
        "      correct += 1\n",
        "  return (correct/float(len(testSet)))*100.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUKeGDzpaLG0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6758077c-3c35-4c3d-ac2c-de475c04f2ee"
      },
      "source": [
        "splitRatio = 0.8\n",
        "dataset = loadcsv()\n",
        "trainingSet, testSet = splitDataset(dataset, splitRatio)\n",
        "print('Split {0} rows into train = {1} and test = {2} rows'.format(len(dataset),len(trainingSet),len(testSet)))\n",
        "  #prepare model\n",
        "summaries = summarizeByClass(trainingSet)\n",
        "  #test model\n",
        "predictions = getPredictions(summaries, testSet)\n",
        "accuracy = getAccuracy(testSet, predictions)\n",
        "print('Accuracy: {0}%'.format(accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Split 1048576 rows into train = 838860 and test = 209716 rows\n",
            "Accuracy: 88.50206946537222%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOQLy3I9sylJ"
      },
      "source": [
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQTFGmUsglVD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "b18f45bd-fe8f-4be2-bb57-4a19b0c6bc98"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn import metrics\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "dataset = loadcsv()\n",
        "splitRatio=0.5\n",
        "trainingSet, testSet = splitDataset(dataset, splitRatio)\n",
        "model = GaussianNB()\n",
        "model.fit(trainingSet, testSet)\n",
        "\n",
        "expected = testSet\n",
        "predicted = model.predict(trainingSet)\n",
        "\n",
        "\n",
        "print(metrics.classification_report(expected, predicted))\n",
        "print(metrics.confusion_matrix(expected, predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.89      0.89    463949\n",
            "         1.0       0.00      0.00      0.00     60327\n",
            "         2.0       0.00      0.00      0.00         7\n",
            "         3.0       0.00      0.00      0.00         2\n",
            "         5.0       0.00      0.00      0.00         1\n",
            "         8.0       0.00      1.00      0.00         1\n",
            "        10.0       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.78    524288\n",
            "   macro avg       0.13      0.27      0.13    524288\n",
            "weighted avg       0.78      0.78      0.78    524288\n",
            "\n",
            "[[411031      0      0     15      0  52903      0]\n",
            " [ 53437      0      0      3      0   6887      0]\n",
            " [     7      0      0      0      0      0      0]\n",
            " [     1      0      0      0      0      1      0]\n",
            " [     1      0      0      0      0      0      0]\n",
            " [     0      0      0      0      0      1      0]\n",
            " [     1      0      0      0      0      0      0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0vrjnJ9uP97"
      },
      "source": [
        "# k-nearest neighbors on the Iris Flowers Dataset\n",
        "from random import seed\n",
        "from random import randrange\n",
        "from csv import reader\n",
        "from math import sqrt\n",
        " \n",
        "# Load a CSV file\n",
        "def load_csv(filename):\n",
        "\tdataset = list()\n",
        "\twith open(filename, 'r') as file:\n",
        "\t\tcsv_reader = reader(file)\n",
        "\t\tfor row in csv_reader:\n",
        "\t\t\tif not row:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tdataset.append(row)\n",
        "\treturn dataset\n",
        " \n",
        "# Convert string column to float\n",
        "def str_column_to_float(dataset, column):\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = float(row[column].strip())\n",
        " \n",
        "# Convert string column to integer\n",
        "def str_column_to_int(dataset, column):\n",
        "\tclass_values = [row[column] for row in dataset]\n",
        "\tunique = set(class_values)\n",
        "\tlookup = dict()\n",
        "\tfor i, value in enumerate(unique):\n",
        "\t\tlookup[value] = i\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = lookup[row[column]]\n",
        "\treturn lookup\n",
        " \n",
        "# Find the min and max values for each column\n",
        "def dataset_minmax(dataset):\n",
        "\tminmax = list()\n",
        "\tfor i in range(len(dataset[0])):\n",
        "\t\tcol_values = [row[i] for row in dataset]\n",
        "\t\tvalue_min = min(col_values)\n",
        "\t\tvalue_max = max(col_values)\n",
        "\t\tminmax.append([value_min, value_max])\n",
        "\treturn minmax\n",
        " \n",
        "# Rescale dataset columns to the range 0-1\n",
        "def normalize_dataset(dataset, minmax):\n",
        "\tfor row in dataset:\n",
        "\t\tfor i in range(len(row)):\n",
        "\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
        " \n",
        "# Split a dataset into k folds\n",
        "def cross_validation_split(dataset, n_folds):\n",
        "\tdataset_split = list()\n",
        "\tdataset_copy = list(dataset)\n",
        "\tfold_size = int(len(dataset) / n_folds)\n",
        "\tfor _ in range(n_folds):\n",
        "\t\tfold = list()\n",
        "\t\twhile len(fold) < fold_size:\n",
        "\t\t\tindex = randrange(len(dataset_copy))\n",
        "\t\t\tfold.append(dataset_copy.pop(index))\n",
        "\t\tdataset_split.append(fold)\n",
        "\treturn dataset_split\n",
        " \n",
        "# Calculate accuracy percentage\n",
        "def accuracy_metric(actual, predicted):\n",
        "\tcorrect = 0\n",
        "\tfor i in range(len(actual)):\n",
        "\t\tif actual[i] == predicted[i]:\n",
        "\t\t\tcorrect += 1\n",
        "\treturn correct / float(len(actual)) * 100.0\n",
        " \n",
        "# Evaluate an algorithm using a cross validation split\n",
        "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
        "\tfolds = cross_validation_split(dataset, n_folds)\n",
        "\tscores = list()\n",
        "\tfor fold in folds:\n",
        "\t\ttrain_set = list(folds)\n",
        "\t\ttrain_set.remove(fold)\n",
        "\t\ttrain_set = sum(train_set, [])\n",
        "\t\ttest_set = list()\n",
        "\t\tfor row in fold:\n",
        "\t\t\trow_copy = list(row)\n",
        "\t\t\ttest_set.append(row_copy)\n",
        "\t\t\trow_copy[-1] = None\n",
        "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
        "\t\tactual = [row[-1] for row in fold]\n",
        "\t\taccuracy = accuracy_metric(actual, predicted)\n",
        "\t\tscores.append(accuracy)\n",
        "\treturn scores\n",
        " \n",
        "# Calculate the Euclidean distance between two vectors\n",
        "def euclidean_distance(row1, row2):\n",
        "\tdistance = 0.0\n",
        "\tfor i in range(len(row1)-1):\n",
        "\t\tdistance += (row1[i] - row2[i])**2\n",
        "\treturn sqrt(distance)\n",
        " \n",
        "# Locate the most similar neighbors\n",
        "def get_neighbors(train, test_row, num_neighbors):\n",
        "\tdistances = list()\n",
        "\tfor train_row in train:\n",
        "\t\tdist = euclidean_distance(test_row, train_row)\n",
        "\t\tdistances.append((train_row, dist))\n",
        "\tdistances.sort(key=lambda tup: tup[1])\n",
        "\tneighbors = list()\n",
        "\tfor i in range(num_neighbors):\n",
        "\t\tneighbors.append(distances[i][0])\n",
        "\treturn neighbors\n",
        " \n",
        "# Make a prediction with neighbors\n",
        "def predict_classification(train, test_row, num_neighbors):\n",
        "\tneighbors = get_neighbors(train, test_row, num_neighbors)\n",
        "\toutput_values = [row[-1] for row in neighbors]\n",
        "\tprediction = max(set(output_values), key=output_values.count)\n",
        "\treturn prediction\n",
        " \n",
        "# kNN Algorithm\n",
        "def k_nearest_neighbors(train, test, num_neighbors):\n",
        "\tpredictions = list()\n",
        "\tfor row in test:\n",
        "\t\toutput = predict_classification(train, row, num_neighbors)\n",
        "\t\tpredictions.append(output)\n",
        "\treturn(predictions)\n",
        " \n",
        "# Test the kNN on the Iris Flowers dataset\n",
        "seed(1)\n",
        "filename = 'output.csv'\n",
        "dataset = load_csv(filename)\n",
        "for i in range(len(dataset[0])-1):\n",
        "\tstr_column_to_float(dataset, i)\n",
        "# convert class column to integers\n",
        "str_column_to_int(dataset, len(dataset[0])-1)\n",
        "# evaluate algorithm\n",
        "n_folds = 2\n",
        "num_neighbors = 3\n",
        "scores = evaluate_algorithm(dataset, k_nearest_neighbors, n_folds, num_neighbors)\n",
        "print('Scores: %s' % scores)\n",
        "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}